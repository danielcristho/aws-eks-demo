{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520ff9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 16:54:24,953\tINFO client_builder.py:244 -- Passing the following kwargs to ray.init() on the server: log_to_driver\n",
      "INFO 2025-10-14 16:54:25,893 serve 131733 -- Connecting to existing Serve app in namespace \"serve\". New http options will not be applied.\n",
      "INFO 2025-10-14 16:54:29,047 serve 131733 -- Application 'default' is ready at http://127.0.0.1:8000/.\n",
      "INFO 2025-10-14 16:54:29,054 serve 131733 -- Deployed app 'default' successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment sent to Ray Serve (GPU requested).\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray import serve\n",
    "\n",
    "ray.init(address=\"ray://10.21.79.111:10001\", allow_multiple=True)\n",
    "\n",
    "@serve.deployment(ray_actor_options={\"num_gpus\": 1})\n",
    "class GPUModel:\n",
    "    async def __call__(self, request):\n",
    "        import torch\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        return {\"device\": device}\n",
    "\n",
    "app = GPUModel.bind()\n",
    "serve.run(app, route_prefix=\"/\")\n",
    "\n",
    "print(\"Deployment sent to Ray Serve\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws-community-day",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
